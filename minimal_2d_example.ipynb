{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# complex\n",
    "from deepdeform.layers.deformation_layer import ImNet, NeuralFlowModel, NeuralFlowDeformer\n",
    "from deepdeform.layers.pointnet_layer import PointNetEncoder\n",
    "from deepdeform.layers.chamfer_layer import ChamferDistKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initial set of points\n",
    "theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# source points\n",
    "x0 = torch.stack((torch.cos(theta),\n",
    "                  torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "torch.manual_seed(2)\n",
    "# create variations of the source\n",
    "all_shapes = [x0]\n",
    "ns = 3\n",
    "for i in range(ns-1):\n",
    "    scale = torch.randn(2) * 0.5 + 2\n",
    "    shift = torch.randn(2) * 2\n",
    "    x_new = x0 * scale + shift\n",
    "    all_shapes.append(x_new)\n",
    "    \n",
    "x_all = torch.stack(all_shapes, dim=0)  # [nshapes, npoints, 3]\n",
    "\n",
    "plt.figure()\n",
    "for i in range(ns):\n",
    "    plt.scatter(x_all[i, :, 0], x_all[i, :, 1], label='x_{}'.format(i))\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader for loading the shapes\n",
    "class DemoLoader(Dataset):\n",
    "    \"\"\"Pytorch Dataset base for loading demo shape pairs.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_all):\n",
    "        \"\"\"Initialize dataloader.\n",
    "        \n",
    "        Args:\n",
    "          x_all: [#shapes, #points, 3] tensor of all shapes\n",
    "        \"\"\"\n",
    "        self.x_all = x_all\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(0.5 * self.n_shapes * (self.n_shapes - 1))\n",
    "    \n",
    "    @property\n",
    "    def n_shapes(self):\n",
    "        return self.x_all.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _idx_to_combinations(idx):\n",
    "        \"\"\"Translate a 1d index to a pair of indices from the combinations.\"\"\"\n",
    "        idx = idx + 1\n",
    "        i = np.ceil((-1+np.sqrt(1+8*idx)) / 2)\n",
    "        j = idx - (i * (i-1)) / 2\n",
    "        return int(i), int(j)-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a random pair of shapes corresponding to idx.\n",
    "        Args:\n",
    "          idx: int, index of the shape pair to return. must be smaller than len(self).\n",
    "        Returns:\n",
    "          verts_i: [npoints, 3] float tensor for point samples from the first shape.\n",
    "          verts_j: [npoints, 3] float tensor for point samples from the second shape.\n",
    "        \"\"\"\n",
    "        i, j = self._idx_to_combinations(idx)\n",
    "        return self.x_all[i], self.x_all[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi shape:  torch.Size([360, 2]) vj shape:  torch.Size([360, 2])\n",
      "dataset # shapes: 3, # combinations: 3\n",
      "batched vi shape:  torch.Size([3, 360, 2]) batched vj shape:  torch.Size([3, 360, 2])\n"
     ]
    }
   ],
   "source": [
    "demo_dataset = DemoLoader(x_all)\n",
    "vi, vj = demo_dataset[0]\n",
    "print(\"vi shape: \", vi.shape, \"vj shape: \", vj.shape)\n",
    "print(\"dataset # shapes: {}, # combinations: {}\".format(demo_dataset.n_shapes, len(demo_dataset)))\n",
    "# bs = len(demo_dataset)\n",
    "bs = min(5, len(demo_dataset))\n",
    "# demo_sampler = RandomSampler(demo_dataset, replacement=True, num_samples=bs) # min(ns, 16))\n",
    "demo_sampler = RandomSampler(demo_dataset, replacement=False)\n",
    "# demo_loader = DataLoader(demo_dataset, batch_size=min(len(demo_dataset), 8), shuffle=False, drop_last=True,\n",
    "#                          sampler=demo_sampler, num_workers=min(len(demo_dataset), 8), pin_memory=True)\n",
    "demo_loader = DataLoader(demo_dataset, batch_size=bs, shuffle=False, drop_last=True,\n",
    "                         sampler=demo_sampler, num_workers=bs, pin_memory=True)\n",
    "for vi, vj in demo_loader:\n",
    "    print(\"batched vi shape: \", vi.shape, \"batched vj shape: \", vj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use containerized deformer along with encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   0 Loss 2.852922\n",
      "Iter   1 Loss 2.886863\n",
      "Iter   2 Loss 2.806329\n",
      "Iter   3 Loss 2.798908\n",
      "Iter   4 Loss 2.678745\n",
      "Iter   5 Loss 2.392188\n",
      "Iter   6 Loss 1.895958\n",
      "Iter   7 Loss 1.253914\n",
      "Iter   8 Loss 0.884275\n",
      "Iter   9 Loss 0.762171\n",
      "Iter  10 Loss 0.563941\n",
      "Iter  11 Loss 0.639992\n",
      "Iter  12 Loss 0.616507\n",
      "Iter  13 Loss 0.540847\n",
      "Iter  14 Loss 0.461660\n",
      "Iter  15 Loss 0.402364\n",
      "Iter  16 Loss 0.408251\n",
      "Iter  17 Loss 0.358596\n",
      "Iter  18 Loss 0.306850\n",
      "Iter  19 Loss 0.248474\n",
      "Iter  20 Loss 0.233059\n",
      "Iter  21 Loss 0.198949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x2aaaabf90950>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/common/software/pytorch/v1.4.0-gpu/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  22 Loss 0.164427\n",
      "Iter  23 Loss 0.113915\n",
      "Iter  24 Loss 0.094318\n",
      "Iter  25 Loss 0.077177\n",
      "Iter  26 Loss 0.055484\n",
      "Iter  27 Loss 0.041077\n",
      "Iter  28 Loss 0.049533\n",
      "Iter  29 Loss 0.048474\n",
      "Iter  30 Loss 0.043562\n",
      "Iter  31 Loss 0.045585\n",
      "Iter  32 Loss 0.039249\n",
      "Iter  33 Loss 0.028692\n",
      "Iter  34 Loss 0.021830\n",
      "Iter  35 Loss 0.021194\n",
      "Iter  36 Loss 0.021568\n",
      "Iter  37 Loss 0.019463\n"
     ]
    }
   ],
   "source": [
    "optim_with_adjoint_gradient = True\n",
    "method = 'dopri5'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "latent_size = 32\n",
    "encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size, dropout_prob=0.0, norm_type='none', nonlinearity='relu')\n",
    "deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=4, s_width=32, method=method, nonlinearity='elu', arch='imnet', \n",
    "                              adjoint=optim_with_adjoint_gradient, rtol=1e-5)\n",
    "\n",
    "# this is an awkward workaround to get gradients for encoder via adjoint solver\n",
    "deformer.add_encoder(encoder)\n",
    "deformer.to(device)\n",
    "encoder = deformer.net.encoder\n",
    "\n",
    "chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "crit = torch.nn.MSELoss()\n",
    "# by wrapping encoder into deformer, no need to add encoder parameters individually\n",
    "optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "\n",
    "encoder.train()\n",
    "deformer.train()\n",
    "    \n",
    "for i in range(200): # train for 100 epochs\n",
    "    for ind, (x_src, x_tar) in enumerate(demo_loader):\n",
    "        x_src = x_src.to(device)\n",
    "        x_tar = x_tar.to(device)\n",
    "        # compute gradients using odeint regular\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # because this is a 2d demo, need to pad zeros for 3rd dimension\n",
    "        x_pad = torch.zeros([x_src.shape[0], x_src.shape[1], 1], device=x_src.device)\n",
    "        x_src_pad = torch.cat([x_src, x_pad], dim=-1)\n",
    "        x_tar_pad = torch.cat([x_tar, x_pad], dim=-1)\n",
    "        \n",
    "        l_src = encoder(x_src_pad)\n",
    "        l_tar = encoder(x_tar_pad)\n",
    "\n",
    "        x_src_ = torch.cat([x_src, x_tar], dim=0)\n",
    "        x_tar_ = torch.cat([x_tar, x_src], dim=0)\n",
    "        l_src_ = torch.cat([l_src, l_tar], dim=0)\n",
    "        l_tar_ = torch.cat([l_tar, l_src], dim=0)\n",
    "\n",
    "        # okay to batch. not okay to call deformer twice (somehow breaks the gradients from adjoint solver)\n",
    "        x_s2t = deformer(x_src_, l_src_, l_tar_)\n",
    "\n",
    "        _, _, dist_s2t = chamfer_dist(x_s2t, x_tar_)\n",
    "    \n",
    "        loss = crit(dist_s2t, torch.zeros_like(dist_s2t))\n",
    "                \n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        if ind == 0:\n",
    "            print(\"Iter {:3d} Loss {:3f}\".format(i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_ = x_src.detach().cpu().numpy()\n",
    "x_tar_ = x_tar.detach().cpu().numpy()\n",
    "s = x_s2t.shape[0]\n",
    "hs = int(s/2)\n",
    "x_s2t_ = x_s2t[:hs].detach().cpu().numpy()\n",
    "x_t2s_ = x_s2t[hs:].detach().cpu().numpy()\n",
    "\n",
    "idx = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_src_[idx, :, 0], x_src_[idx, :, 1], label='source')\n",
    "plt.scatter(x_tar_[idx, :, 0], x_tar_[idx, :, 1], label='target')\n",
    "plt.scatter(x_s2t_[idx, :, 0], x_s2t_[idx, :, 1], label='src2tar')\n",
    "plt.scatter(x_t2s_[idx, :, 0], x_t2s_[idx, :, 1], label='tar2src')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous code that converges with adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "optim_with_adjoint_gradient = True\n",
    "method = 'dopri5'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "latent_size = 32\n",
    "deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "                              adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "crit = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "\n",
    "def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False):\n",
    "    optim.zero_grad()\n",
    "    deformer.adjoint = use_adjoint\n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], x_src.shape[1], 1], device=x_src.device)], dim=-1)\n",
    "        x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], x_tar.shape[1], 1], device=x_tar.device)], dim=-1)\n",
    "        l_src = encoder(x_src_pad)\n",
    "        l_tar = encoder(x_tar_pad)\n",
    "        \n",
    "    x_s2t = deformer(x_src, l_src, l_tar)\n",
    "#     x_t2s = deformer(x_tar, l_tar, l_src)\n",
    "    _, _, dist_s2t = chamfer_dist(x_s2t, x_tar)\n",
    "#     _, _, dist_t2s = chamfer_dist(x_t2s, x_src)\n",
    "    loss_s2t = crit(dist_s2t, torch.zeros_like(dist_s2t))\n",
    "#     loss_t2s = crit(dist_t2s, torch.zeros_like(dist_t2s))\n",
    "#     loss = loss_s2t+loss_t2s\n",
    "    loss = loss_s2t\n",
    "    loss.backward()\n",
    "        \n",
    "    return x_s2t, loss, optim\n",
    "    \n",
    "for i in range(200):    \n",
    "    for ind, (x_src, x_tar) in enumerate(demo_loader):\n",
    "        x_src = x_src.to(device)\n",
    "        x_tar = x_tar.to(device)\n",
    "        # compute gradients using odeint regular\n",
    "        x_s2t_reg, loss, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=optim_with_adjoint_gradient)\n",
    "\n",
    "        optim.step()\n",
    "    \n",
    "    print(\"Iter {:3d} Loss {:3f}\".format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# optim_with_adjoint_gradient = True\n",
    "# method = 'dopri5'\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# latent_size = 32\n",
    "# deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "#                               adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "# encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "# chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False):\n",
    "#     optim.zero_grad()\n",
    "#     deformer.adjoint = use_adjoint\n",
    "#     with torch.no_grad():\n",
    "#         encoder.eval()\n",
    "#         x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], 1], device=x_src.device)], dim=-1)\n",
    "#         x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], 1], device=x_tar.device)], dim=-1)\n",
    "#         x_src_tar_pad = torch.stack([x_src_pad, x_tar_pad], dim=0)\n",
    "#         x_src_tar = torch.stack([x_src, x_tar], dim=0)\n",
    "#         l_src_tar = encoder(x_src_tar_pad)\n",
    "        \n",
    "#     x_s2t = deformer(x_src_tar, l_src_tar, l_src_tar[[1, 0]])\n",
    "#     _, _, dist = chamfer_dist(x_s2t, x_src_tar[[1, 0]])\n",
    "#     loss = crit(dist, torch.zeros_like(dist))\n",
    "    \n",
    "#     loss.backward()\n",
    "        \n",
    "#     return x_s2t, loss, optim\n",
    "    \n",
    "# for i in range(200):    \n",
    "#     # compute gradients using odeint regular\n",
    "#     x_s2t_reg, loss, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=optim_with_adjoint_gradient)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "#     print(\"Iter {:3d} Loss {:3f}\".format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_ = x_src.detach().cpu().numpy()\n",
    "x_tar_ = x_tar.detach().cpu().numpy()\n",
    "x_s2t_reg_ = x_s2t_reg[0].detach().cpu().numpy()\n",
    "x_t2s_reg_ = x_s2t_reg[1].detach().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_src_[:, 0], x_src_[:, 1], label='source')\n",
    "plt.scatter(x_tar_[:, 0], x_tar_[:, 1], label='target')\n",
    "plt.scatter(x_s2t_reg_[:, 0], x_s2t_reg_[:, 1], label='src2tar')\n",
    "plt.scatter(x_t2s_reg_[:, 0], x_t2s_reg_[:, 1], label='tar2src')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previos testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # class ODEFunc(nn.Module):\n",
    "\n",
    "# #     def __init__(self):\n",
    "# #         super(ODEFunc, self).__init__()\n",
    "# #         self.net = ImNet(dim=2, in_features=1, out_features=2, nonlinearity='elu')\n",
    "    \n",
    "# #         for m in self.net.modules():\n",
    "# #             if isinstance(m, nn.Linear):\n",
    "# #                 nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "# #                 nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "# #     def forward(self, t, y):\n",
    "# #         t_ = t.expand([y.shape[0], 1])\n",
    "# #         yt = torch.cat([y, t_], dim=-1)\n",
    "# #         return self.net(yt)\n",
    "\n",
    "    \n",
    "# class ODEFunc(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(ODEFunc, self).__init__()\n",
    "#         latdim = 32\n",
    "#         self.net = NeuralFlowModel(dim=2, latent_size=latdim, f_nlayers=4, f_width=32, \n",
    "#                  s_nlayers=3, s_width=3, nonlinearity='elu', conformal=False, arch='imnet')\n",
    "#         lat = torch.ones([1, latdim]).float().to(device)\n",
    "#         self.net.update_latents(lat*(-1), lat)\n",
    "        \n",
    "#     def forward(self, t, y):\n",
    "#         if len(y.shape) == 2:\n",
    "#             return self.net(t, y[None])[0]\n",
    "#         else:\n",
    "#             return self.net(t, y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_with_adjoint_gradient = False\n",
    "# method = 'dopri5'\n",
    "\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# func = ODEFunc().to(device)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# optim = torch.optim.Adam(func.parameters(), lr=3e-4)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# #DEBUG\n",
    "# self = func.net\n",
    "\n",
    "# def integrate(func, x_src, x_tar, timelapse, integrator, optim):\n",
    "#     optim.zero_grad()\n",
    "#     x_prd = integrator(func, x_src, timelapse, method=method, rtol=1e-5)[1]\n",
    "#     loss = crit(x_prd, x_tar)  # l2 norm between predict and target\n",
    "#     loss.backward()\n",
    "#     grad = [v.grad.clone() for v in func.parameters()]\n",
    "#     return x_prd, grad, loss, optim\n",
    "    \n",
    "# for i in range(100):\n",
    "#     timelapse = torch.tensor([0., 1.]).to(device)\n",
    "    \n",
    "# #     if optim_with_adjoint_gradient:\n",
    "# #         # compute gradients using odeint regular\n",
    "# #         x_prd_reg, grad_reg, loss_reg, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint, optim)\n",
    "\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_prd_adj, grad_adj, loss_adj, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint_adjoint, optim)\n",
    "        \n",
    "# #         optim.step()\n",
    "# #     else:\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_prd_adj, grad_adj, loss_adj, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint_adjoint, optim)\n",
    "        \n",
    "#     # compute gradients using odeint regular\n",
    "#     x_prd_reg, grad_reg, loss_reg, optim = integrate(func, x_src, x_tar, \n",
    "#                                                      timelapse, odeint, optim)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "# #     # DEBUG\n",
    "# #     print(func.net.sign_net(func.net.latent_target - func.net.latent_source))\n",
    "    \n",
    "# #     # compare relative differences\n",
    "# #     rel_diff = [torch.mean(torch.abs(g_reg - g_adj) / torch.abs(g_reg)) \n",
    "# #                 for g_reg, g_adj in zip(grad_reg, grad_adj)]\n",
    "# #     rel_diff = torch.mean(torch.tensor(rel_diff))\n",
    "# #     print(\"Iter {:3d}, rel_diff {:3f}, Loss_reg {:.3f}, Loss_adj {:.3f}\".format(\n",
    "# #           i, rel_diff.item(), loss_reg.item(), loss_adj.item()))\n",
    "#     print(\"DEBUG Iter {:3d}, Loss {:3f}\".format(i, loss_reg.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_src_ = x_src.detach().cpu().numpy()\n",
    "# x_tar_ = x_tar.detach().cpu().numpy()\n",
    "# x_prd_reg_ = x_prd_reg.detach().cpu().numpy()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src_[:, 0], x_src_[:, 1], label='source')\n",
    "# plt.scatter(x_tar_[:, 0], x_tar_[:, 1], label='target')\n",
    "# plt.scatter(x_prd_reg_[:, 0], x_prd_reg_[:, 1], label='predict')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = func.net\n",
    "# t = 1\n",
    "# print(self.latent_source + t * (self.latent_target - self.latent_source))\n",
    "# print(torch.norm(self.latent_target - self.latent_source, dim=-1)[:, None, None])\n",
    "# print(self.sign_net(self.latent_target - self.latent_source))\n",
    "# print(self.sign_net(self.latent_source - self.latent_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_with_adjoint_gradient = False\n",
    "# method = 'dopri5'\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# latent_size = 32\n",
    "# deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "#                               adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "# encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "# chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# # optim = torch.optim.Adam(list(deformer.parameters())+list(encoder.parameters()), lr=1e-3)\n",
    "# optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True):\n",
    "#     optim.zero_grad()\n",
    "#     deformer.adjoint = use_adjoint\n",
    "#     x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], 1], device=x_src.device)], dim=-1)\n",
    "#     x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], 1], device=x_tar.device)], dim=-1)\n",
    "#     x_src_tar_pad = torch.stack([x_src_pad, x_tar_pad], dim=0)\n",
    "#     x_src_tar = torch.stack([x_src, x_tar], dim=0)\n",
    "#     l_src_tar = encoder(x_src_tar_pad)\n",
    "# #     l_src_tar\n",
    "#     l_tar_src = l_src_tar[[1, 0]]\n",
    "#     x_s2t_t2s = deformer(x_src_tar, l_src_tar, l_tar_src)\n",
    "#     x_s2t = x_s2t_t2s[0]\n",
    "#     x_t2s = x_s2t_t2s[1]\n",
    "    \n",
    "#     # l2 norm between predict and target\n",
    "# #     _, _, dist = chamfer_dist(x_s2t_t2s, x_src_tar[[1, 0]])\n",
    "# #     loss = crit(dist, torch.zeros_like(dist))\n",
    "#     loss = crit(x_s2t_t2s[0], x_src_tar[1])\n",
    "#     loss.backward()\n",
    "# #     grad = [v.grad.clone() for v in list(deformer.parameters())+list(encoder.parameters())]\n",
    "#     for name, v in list(deformer.named_parameters())+list(encoder.named_parameters()):\n",
    "#         if v.grad is None:\n",
    "#             print(name)\n",
    "#     grad = [v.grad.clone() for v in list(deformer.parameters())+list(encoder.parameters())]\n",
    "        \n",
    "#     return x_s2t, x_t2s, grad, loss, optim\n",
    "    \n",
    "# for i in range(100):    \n",
    "# #     if optim_with_adjoint_gradient:\n",
    "# #         # compute gradients using odeint regular\n",
    "# #         x_s2t_reg, x_t2s_reg, grad_reg, loss_reg, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False)\n",
    "# #         break\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_s2t_adj, x_t2s_adj, grad_adj, loss_adj, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True)\n",
    "        \n",
    "# #         optim.step()\n",
    "# #     else:\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_s2t_adj, x_t2s_adj, grad_adj, loss_adj, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True)\n",
    "# #         break\n",
    "#     # compute gradients using odeint regular\n",
    "#     x_s2t_reg, x_t2s_reg, grad_reg, loss_reg, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "# #     # compare relative differences\n",
    "# #     rel_diff = [torch.mean(torch.abs(g_reg - g_adj) / torch.abs(g_reg)) \n",
    "# #                 for g_reg, g_adj in zip(grad_reg, grad_adj)]\n",
    "# #     rel_diff = torch.mean(torch.tensor(rel_diff))\n",
    "# #     print(\"Iter {:3d}, rel_diff {:3f}, Loss_reg {:.3f}, Loss_adj {:.3f}\".format(\n",
    "# #           i, rel_diff.item(), loss_reg.item(), loss_adj.item()))\n",
    "#     print(\"Iter {:3d} Loss {:3f}\".format(i, loss_reg.item()))\n",
    "    \n",
    "#     # take a step using odeint regular\n",
    "# #     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.4.0-gpu",
   "language": "python",
   "name": "pytorch-v1.4.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
