{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# complex\n",
    "from deepdeform_debug.layers.deformation_layer import ImNet, NeuralFlowModel, NeuralFlowDeformer\n",
    "from deepdeform_debug.layers.pointnet_layer import PointNetEncoder\n",
    "from deepdeform_debug.layers.chamfer_layer import ChamferDistKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initial set of points\n",
    "theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# source points\n",
    "x0 = torch.stack((torch.cos(theta),\n",
    "                  torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "torch.manual_seed(2)\n",
    "# create variations of the source\n",
    "all_shapes = [x0]\n",
    "ns = 36\n",
    "for i in range(ns-1):\n",
    "    scale = torch.randn(2) * 0.5 + 2\n",
    "    shift = torch.randn(2) * 2\n",
    "    x_new = x0 * scale + shift\n",
    "    all_shapes.append(x_new)\n",
    "    \n",
    "x_all = torch.stack(all_shapes, dim=0)  # [nshapes, npoints, 3]\n",
    "\n",
    "plt.figure()\n",
    "for i in range(ns):\n",
    "    plt.scatter(x_all[i, :, 0], x_all[i, :, 1], label='x_{}'.format(i))\n",
    "plt.axis('equal')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test encoderless learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset # shapes: 36, # combinations: 630\n",
      "torch.Size([32]) torch.Size([32]) batched vi shape:  torch.Size([32, 360, 2]) batched vj shape:  torch.Size([32, 360, 2])\n"
     ]
    }
   ],
   "source": [
    "# dataloader for loading the shapes\n",
    "class DemoLoader(Dataset):\n",
    "    \"\"\"Pytorch Dataset base for loading demo shape pairs.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_all):\n",
    "        \"\"\"Initialize dataloader.\n",
    "        \n",
    "        Args:\n",
    "          x_all: [#shapes, #points, 3] tensor of all shapes\n",
    "        \"\"\"\n",
    "        self.x_all = x_all\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(0.5 * self.n_shapes * (self.n_shapes - 1))\n",
    "    \n",
    "    @property\n",
    "    def n_shapes(self):\n",
    "        return self.x_all.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _idx_to_combinations(idx):\n",
    "        \"\"\"Translate a 1d index to a pair of indices from the combinations.\"\"\"\n",
    "        idx = idx + 1\n",
    "        i = np.ceil((-1+np.sqrt(1+8*idx)) / 2)\n",
    "        j = idx - (i * (i-1)) / 2\n",
    "        return int(i), int(j)-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a random pair of shapes corresponding to idx.\n",
    "        Args:\n",
    "          idx: int, index of the shape pair to return. must be smaller than len(self).\n",
    "        Returns:\n",
    "          verts_i: [npoints, 3] float tensor for point samples from the first shape.\n",
    "          verts_j: [npoints, 3] float tensor for point samples from the second shape.\n",
    "        \"\"\"\n",
    "        i, j = self._idx_to_combinations(idx)\n",
    "        return i, j, self.x_all[i], self.x_all[j]\n",
    "\n",
    "\n",
    "demo_dataset = DemoLoader(x_all)\n",
    "# vi, vj = demo_dataset[0]\n",
    "# print(\"vi shape: \", vi.shape, \"vj shape: \", vj.shape)\n",
    "print(\"dataset # shapes: {}, # combinations: {}\".format(demo_dataset.n_shapes, len(demo_dataset)))\n",
    "# bs = len(demo_dataset)\n",
    "bs = min(32, len(demo_dataset))\n",
    "# demo_sampler = RandomSampler(demo_dataset, replacement=True, num_samples=bs) # min(ns, 16))\n",
    "demo_sampler = RandomSampler(demo_dataset, replacement=False)\n",
    "# demo_loader = DataLoader(demo_dataset, batch_size=min(len(demo_dataset), 8), shuffle=False, drop_last=True,\n",
    "#                          sampler=demo_sampler, num_workers=min(len(demo_dataset), 8), pin_memory=True)\n",
    "demo_loader = DataLoader(demo_dataset, batch_size=bs, shuffle=False, drop_last=True,\n",
    "                         sampler=demo_sampler, num_workers=bs, pin_memory=True)\n",
    "for i, j, vi, vj in demo_loader:\n",
    "    print(i.shape, j.shape, \"batched vi shape: \", vi.shape, \"batched vj shape: \", vj.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   0 Loss 5.627739 Beta 0.099000\n",
      "Iter  25 Loss 2.527228 Beta 0.110421\n",
      "Iter  50 Loss 1.965888 Beta 0.109701\n",
      "Iter  75 Loss 1.299451 Beta 0.109636\n",
      "Iter 100 Loss 0.633372 Beta 0.110497\n",
      "Iter 125 Loss 1.269403 Beta 0.110911\n",
      "Iter 150 Loss 0.919254 Beta 0.110940\n",
      "Iter 175 Loss 0.660774 Beta 0.112524\n",
      "Iter 200 Loss 0.578264 Beta 0.113155\n",
      "Iter 225 Loss 0.457690 Beta 0.114740\n",
      "Iter 250 Loss 0.402540 Beta 0.114981\n",
      "Iter 275 Loss 0.455683 Beta 0.115081\n",
      "Iter 300 Loss 0.383621 Beta 0.115395\n",
      "Iter 325 Loss 0.284550 Beta 0.115859\n",
      "Iter 350 Loss 0.379148 Beta 0.115827\n",
      "Iter 375 Loss 0.484676 Beta 0.116650\n",
      "Iter 400 Loss 0.276511 Beta 0.117389\n",
      "Iter 425 Loss 0.169455 Beta 0.117535\n",
      "Iter 450 Loss 0.174351 Beta 0.117625\n",
      "Iter 475 Loss 0.278227 Beta 0.117235\n",
      "Iter 500 Loss 0.201666 Beta 0.117615\n",
      "Iter 525 Loss 0.221193 Beta 0.117438\n",
      "Iter 550 Loss 0.222829 Beta 0.117563\n",
      "Iter 575 Loss 0.207613 Beta 0.117343\n",
      "Iter 600 Loss 0.217992 Beta 0.117692\n",
      "Iter 625 Loss 0.130388 Beta 0.118312\n",
      "Iter 650 Loss 0.150607 Beta 0.118417\n",
      "Iter 675 Loss 0.131901 Beta 0.118922\n",
      "Iter 700 Loss 0.170843 Beta 0.119077\n",
      "Iter 725 Loss 0.190766 Beta 0.119368\n",
      "Iter 750 Loss 0.205079 Beta 0.119297\n",
      "Iter 775 Loss 0.153124 Beta 0.119552\n",
      "Iter 800 Loss 0.094119 Beta 0.119236\n",
      "Iter 825 Loss 0.154442 Beta 0.119632\n",
      "Iter 850 Loss 0.117179 Beta 0.119823\n",
      "Iter 875 Loss 0.147697 Beta 0.119915\n",
      "Iter 900 Loss 0.090379 Beta 0.120207\n",
      "Iter 925 Loss 0.133726 Beta 0.119866\n",
      "Iter 950 Loss 0.112268 Beta 0.120038\n",
      "Iter 975 Loss 0.134358 Beta 0.119998\n",
      "Iter 1000 Loss 0.120171 Beta 0.120310\n",
      "Iter 1025 Loss 0.116229 Beta 0.120404\n",
      "Iter 1050 Loss 0.081021 Beta 0.120543\n",
      "Iter 1075 Loss 0.116209 Beta 0.120817\n",
      "Iter 1100 Loss 0.105244 Beta 0.120550\n",
      "Iter 1125 Loss 0.178346 Beta 0.120335\n",
      "Iter 1150 Loss 0.091604 Beta 0.120565\n",
      "Iter 1175 Loss 0.077894 Beta 0.120721\n",
      "Iter 1200 Loss 0.092203 Beta 0.120759\n",
      "Iter 1225 Loss 0.062340 Beta 0.121040\n",
      "Iter 1250 Loss 0.102887 Beta 0.121168\n",
      "Iter 1275 Loss 0.089768 Beta 0.121263\n",
      "Iter 1300 Loss 0.106758 Beta 0.121169\n",
      "Iter 1325 Loss 0.072939 Beta 0.121089\n",
      "Iter 1350 Loss 0.042106 Beta 0.121130\n",
      "Iter 1375 Loss 0.053944 Beta 0.121254\n",
      "Iter 1400 Loss 0.069056 Beta 0.121083\n",
      "Iter 1425 Loss 0.052564 Beta 0.120845\n",
      "Iter 1450 Loss 0.051704 Beta 0.120678\n",
      "Iter 1475 Loss 0.081516 Beta 0.120774\n",
      "Iter 1500 Loss 0.115545 Beta 0.120451\n",
      "Iter 1525 Loss 0.108790 Beta 0.120107\n",
      "Iter 1550 Loss 0.059620 Beta 0.120226\n",
      "Iter 1575 Loss 0.058455 Beta 0.119853\n",
      "Iter 1600 Loss 0.037414 Beta 0.119965\n",
      "Iter 1625 Loss 0.083842 Beta 0.119920\n",
      "Iter 1650 Loss 0.043144 Beta 0.119991\n",
      "Iter 1675 Loss 0.053000 Beta 0.119864\n",
      "Iter 1700 Loss 0.044372 Beta 0.119965\n",
      "Iter 1725 Loss 0.040761 Beta 0.119955\n",
      "Iter 1750 Loss 0.066686 Beta 0.119588\n",
      "Iter 1775 Loss 0.040367 Beta 0.119602\n",
      "Iter 1800 Loss 0.047961 Beta 0.119558\n",
      "Iter 1825 Loss 0.096179 Beta 0.119137\n",
      "Iter 1850 Loss 0.033432 Beta 0.118987\n",
      "Iter 1875 Loss 0.028154 Beta 0.119045\n",
      "Iter 1900 Loss 0.112100 Beta 0.118645\n",
      "Iter 1925 Loss 0.036968 Beta 0.118254\n",
      "Iter 1950 Loss 0.046030 Beta 0.118047\n",
      "Iter 1975 Loss 0.070119 Beta 0.118249\n",
      "Iter 2000 Loss 0.036431 Beta 0.118045\n",
      "Iter 2025 Loss 0.051997 Beta 0.117654\n",
      "Iter 2050 Loss 0.070695 Beta 0.116963\n",
      "Iter 2075 Loss 0.037336 Beta 0.117158\n",
      "Iter 2100 Loss 0.034043 Beta 0.116937\n",
      "Iter 2125 Loss 0.021145 Beta 0.116884\n",
      "Iter 2150 Loss 0.017194 Beta 0.116631\n",
      "Iter 2175 Loss 0.081962 Beta 0.116362\n",
      "Iter 2200 Loss 0.038928 Beta 0.116301\n",
      "Iter 2225 Loss 0.023575 Beta 0.116529\n",
      "Iter 2250 Loss 0.021489 Beta 0.116101\n",
      "Iter 2275 Loss 0.069038 Beta 0.115929\n",
      "Iter 2300 Loss 0.056822 Beta 0.115521\n",
      "Iter 2325 Loss 0.028037 Beta 0.115681\n",
      "Iter 2350 Loss 0.035592 Beta 0.115696\n",
      "Iter 2375 Loss 0.019579 Beta 0.115705\n",
      "Iter 2400 Loss 0.046993 Beta 0.115474\n",
      "Iter 2425 Loss 0.036303 Beta 0.115406\n",
      "Iter 2450 Loss 0.024980 Beta 0.115123\n",
      "Iter 2475 Loss 0.061841 Beta 0.114779\n",
      "Iter 2500 Loss 0.038638 Beta 0.114833\n",
      "Iter 2525 Loss 0.031629 Beta 0.114395\n",
      "Iter 2550 Loss 0.030883 Beta 0.114247\n",
      "Iter 2575 Loss 0.035199 Beta 0.114365\n",
      "Iter 2600 Loss 0.017685 Beta 0.114217\n",
      "Iter 2625 Loss 0.028833 Beta 0.114302\n",
      "Iter 2650 Loss 0.050801 Beta 0.114003\n",
      "Iter 2675 Loss 0.045004 Beta 0.113596\n",
      "Iter 2700 Loss 0.035136 Beta 0.113337\n",
      "Iter 2725 Loss 0.023041 Beta 0.113446\n",
      "Iter 2750 Loss 0.038153 Beta 0.113362\n",
      "Iter 2775 Loss 0.035499 Beta 0.113047\n",
      "Iter 2800 Loss 0.038640 Beta 0.112720\n",
      "Iter 2825 Loss 0.035777 Beta 0.112184\n",
      "Iter 2850 Loss 0.017860 Beta 0.111965\n",
      "Iter 2875 Loss 0.020859 Beta 0.111836\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8967af5d934f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx_s2t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_src_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_src_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_tar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_s2t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchamfer_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_s2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_s2t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/DeepDeform/deepdeform_debug/layers/chamfer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tar)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0msrc_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mtar_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         batch_tar_idx = (torch.from_numpy(self.find_batch_nn_id(src_np, tar_np, njobs=self.njobs))\n\u001b[0m\u001b[1;32m    141\u001b[0m                          \u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                          .to(device))  # [b, m]\n",
      "\u001b[0;32m~/codes/DeepDeform/deepdeform_debug/layers/chamfer_layer.py\u001b[0m in \u001b[0;36mfind_batch_nn_id\u001b[0;34m(self, src, tar, njobs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mbatch_nn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_nn_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mbatch_nn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfind_nn_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_nn_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/DeepDeform/deepdeform_debug/layers/chamfer_layer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mbatch_nn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_nn_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mbatch_nn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfind_nn_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_nn_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codes/DeepDeform/deepdeform_debug/layers/chamfer_layer.py\u001b[0m in \u001b[0;36mfind_nn_id\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m     54\u001b[0m     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcKDTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim_with_adjoint_gradient = False\n",
    "method = 'rk4'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "latent_size = 64\n",
    "deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=64, s_nlayers=4, s_width=32, method=method, nonlinearity='leakyrelu', arch='imnet', \n",
    "                              adjoint=optim_with_adjoint_gradient, rtol=1e-4, conformal=False)\n",
    "deformer.to(device)\n",
    "lats = torch.nn.Parameter(torch.randn(ns, latent_size), requires_grad=True)\n",
    "\n",
    "\n",
    "chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "crit = torch.nn.MSELoss()\n",
    "# by wrapping encoder into deformer, no need to add encoder parameters individually\n",
    "optim = torch.optim.Adam(list(deformer.parameters()) + [lats], lr=1e-3)\n",
    "\n",
    "lats = lats.to(device)\n",
    "\n",
    "deformer.train()\n",
    "\n",
    "\n",
    "step = 0\n",
    "for i in range(400): # train for 100 epochs\n",
    "    for ind, (ii, jj, x_src, x_tar) in enumerate(demo_loader):\n",
    "        x_src = x_src.to(device)\n",
    "        x_tar = x_tar.to(device)\n",
    "        # compute gradients using odeint regular\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # because this is a 2d demo, need to pad zeros for 3rd dimension\n",
    "        x_pad = torch.zeros([x_src.shape[0], x_src.shape[1], 1], device=x_src.device)\n",
    "        x_src_pad = torch.cat([x_src, x_pad], dim=-1)\n",
    "        x_tar_pad = torch.cat([x_tar, x_pad], dim=-1)\n",
    "        \n",
    "        l_src = lats[ii]\n",
    "        l_tar = lats[jj]\n",
    "\n",
    "        x_src_ = torch.cat([x_src, x_tar], dim=0)\n",
    "        x_tar_ = torch.cat([x_tar, x_src], dim=0)\n",
    "        l_src_ = torch.cat([l_src, l_tar], dim=0)\n",
    "        l_tar_ = torch.cat([l_tar, l_src], dim=0)\n",
    "\n",
    "        # okay to batch. not okay to call deformer twice (somehow breaks the gradients from adjoint solver)\n",
    "        x_s2t = deformer(x_src_, l_src_, l_tar_)\n",
    "\n",
    "        _, _, dist_s2t = chamfer_dist(x_s2t, x_tar_)\n",
    "    \n",
    "        loss = crit(dist_s2t, torch.zeros_like(dist_s2t))\n",
    "                \n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 25 == 0:\n",
    "            print(\"Iter {:3d} Loss {:3f} Beta {:3f}\".format(step, loss.item(), deformer.net.beta.item()))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize source and target\n",
    "x_src_ = x_src.detach().cpu().numpy()\n",
    "x_tar_ = x_tar.detach().cpu().numpy()\n",
    "s = x_s2t.shape[0]\n",
    "hs = int(s/2)\n",
    "x_s2t_ = x_s2t[:hs].detach().cpu().numpy()\n",
    "x_t2s_ = x_s2t[hs:].detach().cpu().numpy()\n",
    "\n",
    "idx = 1\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x_src_[idx, :, 0], x_src_[idx, :, 1], label='source')\n",
    "plt.scatter(x_tar_[idx, :, 0], x_tar_[idx, :, 1], label='target')\n",
    "plt.scatter(x_s2t_[idx, :, 0], x_s2t_[idx, :, 1], label='src2tar')\n",
    "plt.scatter(x_t2s_[idx, :, 0], x_t2s_[idx, :, 1], label='tar2src')\n",
    "\n",
    "# n = x_src_.shape[1]\n",
    "# for i in range(n):\n",
    "#     plt.plot([x_src_[idx, i, 0], x_s2t_[idx, i, 0]], [x_src_[idx, i, 1], x_s2t_[idx, i, 1]], color='black')\n",
    "    \n",
    "# visualize flow field\n",
    "t = 0.5\n",
    "r = 15\n",
    "l = torch.linspace(-8, 8, r)\n",
    "xy = torch.stack(torch.meshgrid(l, l), dim=-1)  # [50, 50, 2]\n",
    "xy = xy.reshape([1, -1, 2]).cuda()\n",
    "\n",
    "deformer.net.update_latents(l_src[idx:idx+1], l_tar[idx:idx+1])\n",
    "v = deformer.net(t, xy).detach().cpu().numpy()\n",
    "# plt.figure(figsize=(8, 8))\n",
    "xy = xy.detach().cpu().numpy()\n",
    "plt.quiver(xy[0, :, 0], xy[0, :, 1], v[0, :, 0], v[0, :, 1])\n",
    "# plt.show()\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous version that works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader for loading the shapes\n",
    "class DemoLoader(Dataset):\n",
    "    \"\"\"Pytorch Dataset base for loading demo shape pairs.\n",
    "    \"\"\"\n",
    "    def __init__(self, x_all):\n",
    "        \"\"\"Initialize dataloader.\n",
    "        \n",
    "        Args:\n",
    "          x_all: [#shapes, #points, 3] tensor of all shapes\n",
    "        \"\"\"\n",
    "        self.x_all = x_all\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(0.5 * self.n_shapes * (self.n_shapes - 1))\n",
    "    \n",
    "    @property\n",
    "    def n_shapes(self):\n",
    "        return self.x_all.shape[0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _idx_to_combinations(idx):\n",
    "        \"\"\"Translate a 1d index to a pair of indices from the combinations.\"\"\"\n",
    "        idx = idx + 1\n",
    "        i = np.ceil((-1+np.sqrt(1+8*idx)) / 2)\n",
    "        j = idx - (i * (i-1)) / 2\n",
    "        return int(i), int(j)-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a random pair of shapes corresponding to idx.\n",
    "        Args:\n",
    "          idx: int, index of the shape pair to return. must be smaller than len(self).\n",
    "        Returns:\n",
    "          verts_i: [npoints, 3] float tensor for point samples from the first shape.\n",
    "          verts_j: [npoints, 3] float tensor for point samples from the second shape.\n",
    "        \"\"\"\n",
    "        i, j = self._idx_to_combinations(idx)\n",
    "        return self.x_all[i], self.x_all[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = DemoLoader(x_all)\n",
    "vi, vj = demo_dataset[0]\n",
    "print(\"vi shape: \", vi.shape, \"vj shape: \", vj.shape)\n",
    "print(\"dataset # shapes: {}, # combinations: {}\".format(demo_dataset.n_shapes, len(demo_dataset)))\n",
    "# bs = len(demo_dataset)\n",
    "bs = min(8, len(demo_dataset))\n",
    "# demo_sampler = RandomSampler(demo_dataset, replacement=True, num_samples=bs) # min(ns, 16))\n",
    "demo_sampler = RandomSampler(demo_dataset, replacement=False)\n",
    "# demo_loader = DataLoader(demo_dataset, batch_size=min(len(demo_dataset), 8), shuffle=False, drop_last=True,\n",
    "#                          sampler=demo_sampler, num_workers=min(len(demo_dataset), 8), pin_memory=True)\n",
    "demo_loader = DataLoader(demo_dataset, batch_size=bs, shuffle=False, drop_last=True,\n",
    "                         sampler=demo_sampler, num_workers=bs, pin_memory=True)\n",
    "for vi, vj in demo_loader:\n",
    "    print(\"batched vi shape: \", vi.shape, \"batched vj shape: \", vj.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use containerized deformer along with encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_with_adjoint_gradient = True\n",
    "method = 'dopri5'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "latent_size = 32\n",
    "encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size, dropout_prob=0.0, norm_type='none', nonlinearity='relu')\n",
    "deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=64, s_nlayers=4, s_width=32, method=method, nonlinearity='leakyrelu', arch='imnet', \n",
    "                              adjoint=optim_with_adjoint_gradient, rtol=1e-4, conformal=False)\n",
    "\n",
    "# this is an awkward workaround to get gradients for encoder via adjoint solver\n",
    "deformer.add_encoder(encoder)\n",
    "deformer.to(device)\n",
    "encoder = deformer.net.encoder\n",
    "\n",
    "chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "crit = torch.nn.MSELoss()\n",
    "# by wrapping encoder into deformer, no need to add encoder parameters individually\n",
    "optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "\n",
    "encoder.train()\n",
    "deformer.train()\n",
    "\n",
    "step = 0\n",
    "for i in range(100): # train for 100 epochs\n",
    "    for ind, (x_src, x_tar) in enumerate(demo_loader):\n",
    "        x_src = x_src.to(device)\n",
    "        x_tar = x_tar.to(device)\n",
    "        # compute gradients using odeint regular\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # because this is a 2d demo, need to pad zeros for 3rd dimension\n",
    "        x_pad = torch.zeros([x_src.shape[0], x_src.shape[1], 1], device=x_src.device)\n",
    "        x_src_pad = torch.cat([x_src, x_pad], dim=-1)\n",
    "        x_tar_pad = torch.cat([x_tar, x_pad], dim=-1)\n",
    "        \n",
    "        l_src = encoder(x_src_pad)\n",
    "        l_tar = encoder(x_tar_pad)\n",
    "\n",
    "        x_src_ = torch.cat([x_src, x_tar], dim=0)\n",
    "        x_tar_ = torch.cat([x_tar, x_src], dim=0)\n",
    "        l_src_ = torch.cat([l_src, l_tar], dim=0)\n",
    "        l_tar_ = torch.cat([l_tar, l_src], dim=0)\n",
    "\n",
    "        # okay to batch. not okay to call deformer twice (somehow breaks the gradients from adjoint solver)\n",
    "        x_s2t = deformer(x_src_, l_src_, l_tar_)\n",
    "\n",
    "        _, _, dist_s2t = chamfer_dist(x_s2t, x_tar_)\n",
    "#         dist_s2t = torch.norm(x_tar_ - x_s2t, dim=-1)\n",
    "    \n",
    "        loss = crit(dist_s2t, torch.zeros_like(dist_s2t))\n",
    "                \n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print(\"Iter {:3d} Loss {:3f} Beta {:3f}\".format(step, loss.item(), deformer.net.beta.item()))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize source and target\n",
    "x_src_ = x_src.detach().cpu().numpy()\n",
    "x_tar_ = x_tar.detach().cpu().numpy()\n",
    "s = x_s2t.shape[0]\n",
    "hs = int(s/2)\n",
    "x_s2t_ = x_s2t[:hs].detach().cpu().numpy()\n",
    "x_t2s_ = x_s2t[hs:].detach().cpu().numpy()\n",
    "\n",
    "idx = 5\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x_src_[idx, :, 0], x_src_[idx, :, 1], label='source')\n",
    "plt.scatter(x_tar_[idx, :, 0], x_tar_[idx, :, 1], label='target')\n",
    "plt.scatter(x_s2t_[idx, :, 0], x_s2t_[idx, :, 1], label='src2tar')\n",
    "plt.scatter(x_t2s_[idx, :, 0], x_t2s_[idx, :, 1], label='tar2src')\n",
    "\n",
    "# n = x_src_.shape[1]\n",
    "# for i in range(n):\n",
    "#     plt.plot([x_src_[idx, i, 0], x_s2t_[idx, i, 0]], [x_src_[idx, i, 1], x_s2t_[idx, i, 1]], color='black')\n",
    "    \n",
    "# visualize flow field\n",
    "t = 0.5\n",
    "r = 15\n",
    "l = torch.linspace(-5, 4, r)\n",
    "xy = torch.stack(torch.meshgrid(l, l), dim=-1)  # [50, 50, 2]\n",
    "xy = xy.reshape([1, -1, 2]).cuda()\n",
    "\n",
    "deformer.net.update_latents(l_src[idx:idx+1], l_tar[idx:idx+1])\n",
    "v = deformer.net(t, xy).detach().cpu().numpy()\n",
    "# plt.figure(figsize=(8, 8))\n",
    "xy = xy.detach().cpu().numpy()\n",
    "plt.quiver(xy[0, :, 0], xy[0, :, 1], v[0, :, 0], v[0, :, 1])\n",
    "# plt.show()\n",
    "    \n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous code that converges with adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "optim_with_adjoint_gradient = True\n",
    "method = 'dopri5'\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "latent_size = 32\n",
    "deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "                              adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "crit = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "\n",
    "def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False):\n",
    "    optim.zero_grad()\n",
    "    deformer.adjoint = use_adjoint\n",
    "    with torch.no_grad():\n",
    "        encoder.eval()\n",
    "        x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], x_src.shape[1], 1], device=x_src.device)], dim=-1)\n",
    "        x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], x_tar.shape[1], 1], device=x_tar.device)], dim=-1)\n",
    "        l_src = encoder(x_src_pad)\n",
    "        l_tar = encoder(x_tar_pad)\n",
    "        \n",
    "    x_s2t = deformer(x_src, l_src, l_tar)\n",
    "#     x_t2s = deformer(x_tar, l_tar, l_src)\n",
    "    _, _, dist_s2t = chamfer_dist(x_s2t, x_tar)\n",
    "#     _, _, dist_t2s = chamfer_dist(x_t2s, x_src)\n",
    "    loss_s2t = crit(dist_s2t, torch.zeros_like(dist_s2t))\n",
    "#     loss_t2s = crit(dist_t2s, torch.zeros_like(dist_t2s))\n",
    "#     loss = loss_s2t+loss_t2s\n",
    "    loss = loss_s2t\n",
    "    loss.backward()\n",
    "        \n",
    "    return x_s2t, loss, optim\n",
    "    \n",
    "for i in range(200):    \n",
    "    for ind, (x_src, x_tar) in enumerate(demo_loader):\n",
    "        x_src = x_src.to(device)\n",
    "        x_tar = x_tar.to(device)\n",
    "        # compute gradients using odeint regular\n",
    "        x_s2t_reg, loss, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=optim_with_adjoint_gradient)\n",
    "\n",
    "        optim.step()\n",
    "    \n",
    "    print(\"Iter {:3d} Loss {:3f}\".format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# optim_with_adjoint_gradient = True\n",
    "# method = 'dopri5'\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# latent_size = 32\n",
    "# deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "#                               adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "# encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "# chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False):\n",
    "#     optim.zero_grad()\n",
    "#     deformer.adjoint = use_adjoint\n",
    "#     with torch.no_grad():\n",
    "#         encoder.eval()\n",
    "#         x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], 1], device=x_src.device)], dim=-1)\n",
    "#         x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], 1], device=x_tar.device)], dim=-1)\n",
    "#         x_src_tar_pad = torch.stack([x_src_pad, x_tar_pad], dim=0)\n",
    "#         x_src_tar = torch.stack([x_src, x_tar], dim=0)\n",
    "#         l_src_tar = encoder(x_src_tar_pad)\n",
    "        \n",
    "#     x_s2t = deformer(x_src_tar, l_src_tar, l_src_tar[[1, 0]])\n",
    "#     _, _, dist = chamfer_dist(x_s2t, x_src_tar[[1, 0]])\n",
    "#     loss = crit(dist, torch.zeros_like(dist))\n",
    "    \n",
    "#     loss.backward()\n",
    "        \n",
    "#     return x_s2t, loss, optim\n",
    "    \n",
    "# for i in range(200):    \n",
    "#     # compute gradients using odeint regular\n",
    "#     x_s2t_reg, loss, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=optim_with_adjoint_gradient)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "#     print(\"Iter {:3d} Loss {:3f}\".format(i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_src_ = x_src.detach().cpu().numpy()\n",
    "x_tar_ = x_tar.detach().cpu().numpy()\n",
    "x_s2t_reg_ = x_s2t_reg[0].detach().cpu().numpy()\n",
    "x_t2s_reg_ = x_s2t_reg[1].detach().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_src_[:, 0], x_src_[:, 1], label='source')\n",
    "plt.scatter(x_tar_[:, 0], x_tar_[:, 1], label='target')\n",
    "plt.scatter(x_s2t_reg_[:, 0], x_s2t_reg_[:, 1], label='src2tar')\n",
    "plt.scatter(x_t2s_reg_[:, 0], x_t2s_reg_[:, 1], label='tar2src')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previos testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initial set of points\n",
    "# theta = torch.linspace(0, 2*np.pi, 361)[:-1]\n",
    "\n",
    "# # source points\n",
    "# x_src = torch.stack((torch.cos(theta),\n",
    "#                      torch.sin(theta)), axis=-1)  # [n, 3]\n",
    "\n",
    "# # target points\n",
    "# x_tar = x_src * 3 + 2\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src[:, 0], x_src[:, 1], label='src')\n",
    "# plt.scatter(x_tar[:, 0], x_tar[:, 1], label='tar')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # class ODEFunc(nn.Module):\n",
    "\n",
    "# #     def __init__(self):\n",
    "# #         super(ODEFunc, self).__init__()\n",
    "# #         self.net = ImNet(dim=2, in_features=1, out_features=2, nonlinearity='elu')\n",
    "    \n",
    "# #         for m in self.net.modules():\n",
    "# #             if isinstance(m, nn.Linear):\n",
    "# #                 nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "# #                 nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "# #     def forward(self, t, y):\n",
    "# #         t_ = t.expand([y.shape[0], 1])\n",
    "# #         yt = torch.cat([y, t_], dim=-1)\n",
    "# #         return self.net(yt)\n",
    "\n",
    "    \n",
    "# class ODEFunc(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(ODEFunc, self).__init__()\n",
    "#         latdim = 32\n",
    "#         self.net = NeuralFlowModel(dim=2, latent_size=latdim, f_nlayers=4, f_width=32, \n",
    "#                  s_nlayers=3, s_width=3, nonlinearity='elu', conformal=False, arch='imnet')\n",
    "#         lat = torch.ones([1, latdim]).float().to(device)\n",
    "#         self.net.update_latents(lat*(-1), lat)\n",
    "        \n",
    "#     def forward(self, t, y):\n",
    "#         if len(y.shape) == 2:\n",
    "#             return self.net(t, y[None])[0]\n",
    "#         else:\n",
    "#             return self.net(t, y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_with_adjoint_gradient = False\n",
    "# method = 'dopri5'\n",
    "\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# func = ODEFunc().to(device)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# optim = torch.optim.Adam(func.parameters(), lr=3e-4)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# #DEBUG\n",
    "# self = func.net\n",
    "\n",
    "# def integrate(func, x_src, x_tar, timelapse, integrator, optim):\n",
    "#     optim.zero_grad()\n",
    "#     x_prd = integrator(func, x_src, timelapse, method=method, rtol=1e-5)[1]\n",
    "#     loss = crit(x_prd, x_tar)  # l2 norm between predict and target\n",
    "#     loss.backward()\n",
    "#     grad = [v.grad.clone() for v in func.parameters()]\n",
    "#     return x_prd, grad, loss, optim\n",
    "    \n",
    "# for i in range(100):\n",
    "#     timelapse = torch.tensor([0., 1.]).to(device)\n",
    "    \n",
    "# #     if optim_with_adjoint_gradient:\n",
    "# #         # compute gradients using odeint regular\n",
    "# #         x_prd_reg, grad_reg, loss_reg, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint, optim)\n",
    "\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_prd_adj, grad_adj, loss_adj, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint_adjoint, optim)\n",
    "        \n",
    "# #         optim.step()\n",
    "# #     else:\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_prd_adj, grad_adj, loss_adj, optim = integrate(func, x_src, x_tar, \n",
    "# #                                                          timelapse, odeint_adjoint, optim)\n",
    "        \n",
    "#     # compute gradients using odeint regular\n",
    "#     x_prd_reg, grad_reg, loss_reg, optim = integrate(func, x_src, x_tar, \n",
    "#                                                      timelapse, odeint, optim)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "# #     # DEBUG\n",
    "# #     print(func.net.sign_net(func.net.latent_target - func.net.latent_source))\n",
    "    \n",
    "# #     # compare relative differences\n",
    "# #     rel_diff = [torch.mean(torch.abs(g_reg - g_adj) / torch.abs(g_reg)) \n",
    "# #                 for g_reg, g_adj in zip(grad_reg, grad_adj)]\n",
    "# #     rel_diff = torch.mean(torch.tensor(rel_diff))\n",
    "# #     print(\"Iter {:3d}, rel_diff {:3f}, Loss_reg {:.3f}, Loss_adj {:.3f}\".format(\n",
    "# #           i, rel_diff.item(), loss_reg.item(), loss_adj.item()))\n",
    "#     print(\"DEBUG Iter {:3d}, Loss {:3f}\".format(i, loss_reg.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_src_ = x_src.detach().cpu().numpy()\n",
    "# x_tar_ = x_tar.detach().cpu().numpy()\n",
    "# x_prd_reg_ = x_prd_reg.detach().cpu().numpy()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(x_src_[:, 0], x_src_[:, 1], label='source')\n",
    "# plt.scatter(x_tar_[:, 0], x_tar_[:, 1], label='target')\n",
    "# plt.scatter(x_prd_reg_[:, 0], x_prd_reg_[:, 1], label='predict')\n",
    "# plt.axis('equal')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = func.net\n",
    "# t = 1\n",
    "# print(self.latent_source + t * (self.latent_target - self.latent_source))\n",
    "# print(torch.norm(self.latent_target - self.latent_source, dim=-1)[:, None, None])\n",
    "# print(self.sign_net(self.latent_target - self.latent_source))\n",
    "# print(self.sign_net(self.latent_source - self.latent_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim_with_adjoint_gradient = False\n",
    "# method = 'dopri5'\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# latent_size = 32\n",
    "# deformer = NeuralFlowDeformer(dim=2, latent_size=latent_size, f_nlayers=6, f_width=32, s_nlayers=3, s_width=3, method=method, nonlinearity='elu', arch='imnet', \n",
    "#                               adjoint=optim_with_adjoint_gradient, rtol=1e-5).to(device)\n",
    "# encoder = PointNetEncoder(nf=32, in_features=3, out_features=latent_size).to(device)\n",
    "\n",
    "# chamfer_dist = ChamferDistKDTree(reduction='mean', njobs=1)\n",
    "# crit = torch.nn.MSELoss()\n",
    "# # optim = torch.optim.Adam(list(deformer.parameters())+list(encoder.parameters()), lr=1e-3)\n",
    "# optim = torch.optim.Adam(list(deformer.parameters()), lr=1e-3)\n",
    "# x_src = x_src.to(device)\n",
    "# x_tar = x_tar.to(device)\n",
    "\n",
    "# def integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True):\n",
    "#     optim.zero_grad()\n",
    "#     deformer.adjoint = use_adjoint\n",
    "#     x_src_pad = torch.cat([x_src, torch.zeros([x_src.shape[0], 1], device=x_src.device)], dim=-1)\n",
    "#     x_tar_pad = torch.cat([x_tar, torch.zeros([x_tar.shape[0], 1], device=x_tar.device)], dim=-1)\n",
    "#     x_src_tar_pad = torch.stack([x_src_pad, x_tar_pad], dim=0)\n",
    "#     x_src_tar = torch.stack([x_src, x_tar], dim=0)\n",
    "#     l_src_tar = encoder(x_src_tar_pad)\n",
    "# #     l_src_tar\n",
    "#     l_tar_src = l_src_tar[[1, 0]]\n",
    "#     x_s2t_t2s = deformer(x_src_tar, l_src_tar, l_tar_src)\n",
    "#     x_s2t = x_s2t_t2s[0]\n",
    "#     x_t2s = x_s2t_t2s[1]\n",
    "    \n",
    "#     # l2 norm between predict and target\n",
    "# #     _, _, dist = chamfer_dist(x_s2t_t2s, x_src_tar[[1, 0]])\n",
    "# #     loss = crit(dist, torch.zeros_like(dist))\n",
    "#     loss = crit(x_s2t_t2s[0], x_src_tar[1])\n",
    "#     loss.backward()\n",
    "# #     grad = [v.grad.clone() for v in list(deformer.parameters())+list(encoder.parameters())]\n",
    "#     for name, v in list(deformer.named_parameters())+list(encoder.named_parameters()):\n",
    "#         if v.grad is None:\n",
    "#             print(name)\n",
    "#     grad = [v.grad.clone() for v in list(deformer.parameters())+list(encoder.parameters())]\n",
    "        \n",
    "#     return x_s2t, x_t2s, grad, loss, optim\n",
    "    \n",
    "# for i in range(100):    \n",
    "# #     if optim_with_adjoint_gradient:\n",
    "# #         # compute gradients using odeint regular\n",
    "# #         x_s2t_reg, x_t2s_reg, grad_reg, loss_reg, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False)\n",
    "# #         break\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_s2t_adj, x_t2s_adj, grad_adj, loss_adj, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True)\n",
    "        \n",
    "# #         optim.step()\n",
    "# #     else:\n",
    "# #         # compute gradients using odeint adjoint\n",
    "# #         x_s2t_adj, x_t2s_adj, grad_adj, loss_adj, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=True)\n",
    "# #         break\n",
    "#     # compute gradients using odeint regular\n",
    "#     x_s2t_reg, x_t2s_reg, grad_reg, loss_reg, optim = integrate(x_src, x_tar, encoder, deformer, optim, use_adjoint=False)\n",
    "\n",
    "#     optim.step()\n",
    "    \n",
    "# #     # compare relative differences\n",
    "# #     rel_diff = [torch.mean(torch.abs(g_reg - g_adj) / torch.abs(g_reg)) \n",
    "# #                 for g_reg, g_adj in zip(grad_reg, grad_adj)]\n",
    "# #     rel_diff = torch.mean(torch.tensor(rel_diff))\n",
    "# #     print(\"Iter {:3d}, rel_diff {:3f}, Loss_reg {:.3f}, Loss_adj {:.3f}\".format(\n",
    "# #           i, rel_diff.item(), loss_reg.item(), loss_adj.item()))\n",
    "#     print(\"Iter {:3d} Loss {:3f}\".format(i, loss_reg.item()))\n",
    "    \n",
    "#     # take a step using odeint regular\n",
    "# #     optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
