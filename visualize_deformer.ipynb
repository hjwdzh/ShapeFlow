{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load deformer and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import trimesh\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "from shapenet_dataloader import ShapeNetMesh\n",
    "from deepdeform.layers.deformation_layer import NeuralFlowDeformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice of checkpoint to load\n",
    "run_dir = \"runs/run_4746_nnnr_nosign\"\n",
    "checkpoint = \"checkpoint_latest.pth.tar_deepdeform_best.pth.tar\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training args\n",
    "args = SimpleNamespace(**json.load(open(os.path.join(run_dir, 'params.json'), 'r')))\n",
    "\n",
    "# setup model\n",
    "deformer = NeuralFlowDeformer(latent_size=args.lat_dims, f_width=args.deformer_nf, s_nlayers=2, \n",
    "                              s_width=5, method=args.solver, nonlinearity=args.nonlin, arch='imnet',\n",
    "                              adjoint=args.adjoint, rtol=args.rtol, atol=args.atol, via_hub=True,\n",
    "                              no_sign_net=(not args.sign_net))\n",
    "lat_params = torch.nn.Parameter(torch.randn(4746, args.lat_dims)*1e-1, requires_grad=True)\n",
    "deformer.add_lat_params(lat_params)\n",
    "deformer.to(device)\n",
    "\n",
    "# load checkpoint\n",
    "resume_dict = torch.load(os.path.join(run_dir, checkpoint))\n",
    "start_ep = resume_dict[\"epoch\"]\n",
    "global_step = resume_dict[\"global_step\"]\n",
    "tracked_stats = resume_dict[\"tracked_stats\"]\n",
    "deformer.load_state_dict(resume_dict[\"deformer_state_dict\"])\n",
    "\n",
    "# dataloader\n",
    "data_root = args.data_root.replace('shapenet_watertight', 'shapenet_simplified')\n",
    "dset = ShapeNetMesh(data_root=data_root, split=\"train\", category=\"chair\", \n",
    "                    normals=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test deformation between a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_idx = 0  # choose between [0, 4745]\n",
    "target_idx = 1  # choose between [0, 4745]\n",
    "\n",
    "_, _, v_src, f_src, v_tar, f_tar = dset.get_pairs(source_idx, target_idx)\n",
    "v_src = v_src.to(device)\n",
    "v_tar = v_tar.to(device)\n",
    "\n",
    "# get the latent codes corresponding to these shapes\n",
    "l_src = deformer.get_lat_params(source_idx)  \n",
    "l_tar = deformer.get_lat_params(target_idx)\n",
    "l_zero = torch.zeros_like(l_src)\n",
    "\n",
    "lat_path = lambda l_src_, l_tar_: torch.stack([l_src_, l_zero, l_tar_], dim=1)\n",
    "\n",
    "# interpolation between source and target\n",
    "steps = 11\n",
    "# source to target\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.4.0-gpu",
   "language": "python",
   "name": "pytorch-v1.4.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
